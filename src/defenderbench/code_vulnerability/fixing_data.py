import os
import logging
import subprocess
from os.path import join as pjoin

import sqlite3
from typing import Optional
import pandas as pd
from tqdm import tqdm

from defenderbench.config import DEFENDERBENCH_CACHE_HOME, DEFENDERBENCH_FORCE_DOWNLOAD
from defenderbench.utils import download

# Installation https://github.com/secureIT-project/CVEfixes/blob/main/INSTALL.md
# Source: https://huggingface.co/datasets/AI4Sec/cti-bench
CVE_FIXES_URL = "https://zenodo.org/records/13118970/files/CVEfixes_v1.0.8.zip"
DEFENDERBENCH_CACHE_CODE_FIXING = pjoin(DEFENDERBENCH_CACHE_HOME, "code_fixing")

DEFENDERBENCH_CACHE_CODE_FIXING_DATA_DB = pjoin(DEFENDERBENCH_CACHE_CODE_FIXING, "CVEfixes_v1.0.8.db")
DEFENDERBENCH_CACHE_CODE_FIXING_DATA_ZIP = pjoin(DEFENDERBENCH_CACHE_CODE_FIXING, "CVEfixes_v1.0.8.zip")
DEFENDERBENCH_CACHE_CODE_FIXING_DATA_GZ = pjoin(DEFENDERBENCH_CACHE_CODE_FIXING, "CVEfixes_v1.0.8.sql.gz")
DEFENDERBENCH_CACHE_CODE_FIXING_DATA = pjoin(DEFENDERBENCH_CACHE_CODE_FIXING, "CVEfixes_v1.0.8.sql")
DEFENDERBENCH_CACHE_CODE_FIXING_DATA_TRAIN = pjoin(DEFENDERBENCH_CACHE_CODE_FIXING, "CVEfixes_train.tsv")
DEFENDERBENCH_CACHE_CODE_FIXING_DATA_TEST = pjoin(DEFENDERBENCH_CACHE_CODE_FIXING, "CVEfixes_test.tsv")


def prepare_code_fixing_data(force=DEFENDERBENCH_FORCE_DOWNLOAD):
    all_files_exist = (
        os.path.exists(DEFENDERBENCH_CACHE_CODE_FIXING_DATA_TRAIN)
        and os.path.exists(DEFENDERBENCH_CACHE_CODE_FIXING_DATA_TEST)
    )
    if all_files_exist and not force:
        return

    download(CVE_FIXES_URL, os.path.dirname(DEFENDERBENCH_CACHE_CODE_FIXING_DATA_ZIP), force=force)

    # Build the SQL database directly from the zip file.
    if not os.path.exists(DEFENDERBENCH_CACHE_CODE_FIXING_DATA_DB) or os.path.getsize(DEFENDERBENCH_CACHE_CODE_FIXING_DATA_DB) == 0:
        subprocess.run(
            f"unzip -p {DEFENDERBENCH_CACHE_CODE_FIXING_DATA_ZIP} CVEfixes_v1.0.8/Data/CVEfixes_v1.0.8.sql.gz | gunzip | tqdm --bytes --total 51688558592 --desc 'Building CVEFixes database' | sqlite3 {DEFENDERBENCH_CACHE_CODE_FIXING_DATA_DB}",
            shell=True,
        )

    print("Building CVEFixes dataset...")

    # Query the database to get the data.
    conn = sqlite3.connect(DEFENDERBENCH_CACHE_CODE_FIXING_DATA_DB)

    # Only look at commits with single file change and associated to a single CVE fix and CWE classification.
    # Additionally we filter out CVE fix associated with more than one commit.
    query = (
        "SELECT f.hash, mc.file_change_id, mc.signature, mc.method_change_id, f.programming_language, f.num_lines_added, f.num_lines_deleted, mc.before_change, mc.code, fixes.cve_id, cwe.cwe_name"
        "\nFROM method_change mc"
        "\nLEFT JOIN file_change f ON mc.file_change_id = f.file_change_id"
        "\nLEFT JOIN fixes ON fixes.hash = f.hash"
        "\nLEFT JOIN cwe_classification ON cwe_classification.cve_id = fixes.cve_id"
        "\nLEFT JOIN cwe ON cwe.cwe_id = cwe_classification.cwe_id"

        "\nWHERE mc.file_change_id IN ("
            "\nSELECT f.file_change_id"
            "\nFROM file_change f"
            "\nWHERE f.hash IN ("
                "\nSELECT c.hash"
                "\nFROM file_change f"
                "\nJOIN commits c ON f.hash = c.hash"
                "\nGROUP BY c.hash"
                "\nHAVING COUNT(f.file_change_id) = 1"
            "\n) AND f.hash IN ("
                "\nSELECT fixes.hash"
                "\nFROM fixes"
                "\nWHERE fixes.cve_id IN ("
                    "\nSELECT cwe_classification.cve_id"
                    "\nFROM cwe_classification"
                    "\nGROUP BY cwe_classification.cve_id"
                    "\nHAVING COUNT(cwe_classification.cwe_id) = 1"
                "\n)"
                "\nGROUP BY fixes.hash"
                "\nHAVING COUNT(fixes.cve_id) = 1"
            "\n) AND f.hash IN ("
                "\nSELECT fixes.hash"
                "\nFROM fixes"
                "\nGROUP BY fixes.cve_id"
                "\nHAVING COUNT(fixes.hash) = 1"
            "\n)"
        "\n)"
    )
    print("Querying the database...")
    query_res = pd.read_sql_query(query, conn)
    logging.info(f"CVEFix: Queried {len(query_res)} commits.")

    # We want commits with only two method changes (i.e., before and after code change). Filter out the rest.
    count = query_res.groupby(['hash']).count()
    count = count[count['method_change_id'] == 2]
    query_res = query_res[query_res['hash'].isin(count.index)]

    # We want the two method changes to be on the same method (according to its signature).
    count = query_res.groupby(['hash', 'file_change_id', 'signature']).count()
    count = count[count['method_change_id'] == 2]
    query_res = query_res[query_res['hash'].isin(count.index.get_level_values('hash'))]

    # Remove CWEs with nonmeaningful names ('Other', '7PK - Errors').
    query_res = query_res[query_res['cwe_name'] != 'Other']
    query_res = query_res[query_res['cwe_name'] != '7PK - Errors']

    # Add another column with code after change
    # Create new table where code before change is in one column and code after change is in another column.
    code_before_change = query_res[query_res['before_change'] == 'True'].drop(columns=['before_change'])
    code_after_change = query_res[query_res['before_change'] == 'False'].drop(columns=['before_change'])
    data = code_before_change.merge(code_after_change, on=['hash', 'file_change_id', 'signature', 'num_lines_added', 'num_lines_deleted', 'cve_id', 'cwe_name', 'programming_language'], suffixes=('_before', '_after'))

    # Keep only programming languages supported by CodeBleu:
    # Python, C, C#, C++, Java, JavaScript, PHP, Go, Ruby, Rust
    data = data[data['programming_language'].isin(['Python', 'C', 'C#', 'C++', 'Java', 'JavaScript', 'PHP', 'Go', 'Ruby', 'Rust'])]

    # Keep only language with more than 30 samples.
    count = data.groupby(['programming_language']).count()
    count = count[count['hash'] > 30]
    data = data[data['programming_language'].isin(count.index)]

    logging.info(f"CVEFix: Total commits after processing: {len(data)}.")

    # Sample 30 examples for each programming language.
    test_data = data.groupby(['programming_language']).apply(lambda x: x.sample(n=30, random_state=42)).reset_index(drop=True)
    # Shuffle the data.
    test_data = test_data.sample(frac=1, random_state=42).reset_index(drop=True)

    # Get the rest of the data as training data.
    train_data = data[~data["hash"].isin(test_data["hash"])]
    # Sample 1 example for each programming language.
    train_data = train_data.groupby(['programming_language']).apply(lambda x: x.sample(n=1, random_state=42)).reset_index(drop=True)

    # Dump the data to disk.
    print("Caching dataset to disk...")
    test_data.to_csv(DEFENDERBENCH_CACHE_CODE_FIXING_DATA_TEST, sep="\t", index=False)
    train_data.to_csv(DEFENDERBENCH_CACHE_CODE_FIXING_DATA_TRAIN, sep="\t", index=False)


def get(name, limit: Optional[int] = None):
    prepare_code_fixing_data()  # make sure the data is ready

    if name == "train":
        return pd.read_csv(DEFENDERBENCH_CACHE_CODE_FIXING_DATA_TRAIN, sep="\t")
    elif name == "test":
        data = pd.read_csv(DEFENDERBENCH_CACHE_CODE_FIXING_DATA_TEST, sep="\t")
        return data[:limit] if limit else data
    else:
        raise ValueError(f"Invalid data name: {name} for CVEFixBasic environment.")
